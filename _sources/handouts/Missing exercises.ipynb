{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88ceb140-eb43-4240-b72b-9750359f00d2",
   "metadata": {},
   "source": [
    "# Missing and Extreme Values\n",
    "\n",
    "## Discussion of Missing Data\n",
    "\n",
    "[Textbook](https://ledatascifi.github.io/ledatascifi-2024/content/03/05c_missingdata.html)\n",
    "\n",
    "**Missing data is prevalent and common feature of real world datasets.**\n",
    "\n",
    "The most important question to ask is \"Why is this variable blank for this observation?\"\n",
    "- Is that variable missing completely randomly, or systematically?\n",
    "- If systematic explanation plausible, this will impact many steps of our analysis. [Gif: Truncation on y.](https://lh6.googleusercontent.com/h_laUnAP-yOolhyqjcHDzAElFHDJiaaO49SmCQaFfVRqZZ369V7KGKTcAozQYxHwVUPi2lGP7HUpMdfUPsngV0_0idyKW-DOvGN0mgydqOSLxeAymloswdQtcoDruoxreg=w1280)\n",
    "\n",
    "Systematic reasons include censoring and truncation mechanisms:\n",
    "- A central bank intervenes to stop an exchange rate falling below or\n",
    "going above certain levels.\n",
    "- Dividends paid by a company may remain zero until earnings reach\n",
    "some threshold value.\n",
    "- A government imposes price controls on some goods.\n",
    "- A survey of only working women, ignoring non-working women.\n",
    "\n",
    "## What **CAN** you do about missing data?\n",
    "\n",
    "(Not \"should\".)\n",
    "\n",
    "Option | Pro | Con \n",
    ":-- | :--- | :---\n",
    "Find it | Basically \"free\" lunch on multiple dimensions | Data collection ain't free\n",
    "**Leave blank.** For each test, use all observations with no missing values for the variables in that specific test. | Doesn't _add_ noise or bias | Less data = less power, non-missing sample might not be representative\n",
    "Deduce value (my height is the same as last year) | When deduction is exact, great | Rarely possible\n",
    "Interpolate (my height in a year is halfway between my recorded height the prior and subsequent year) | In some settings, this adds viable data | Can artificially smooth time trends and cross sectional differences, often not possible\n",
    "Fill with other values (median, mean, \"fancy\" imputation) | Common in prediction problems because it can \"allow\" you to use more data | Lots (see below), but tl;dr: Don't do this for causal inference and non-prediction problems\n",
    "\n",
    "## My recommendations \n",
    "\n",
    "1. Find it. The remaining options aren't super. \n",
    "1. If you can deduce the correct value, go ahead\n",
    "1. Otherwise, tend towards leaving blank \n",
    "    - On a test-by-test basis, you'll delete or ignore observations where any variable in the test has missing values.\n",
    "    - Most common choice in finance research, and if your question is about _causal inference_, the only choice.\n",
    "1. Create a flag (binary variable) to indicate observations with missing values.\n",
    "    - Then replace the NANs in the original variable with a consistent value, such as 0 or -999. \n",
    "    - In regressions, you must include both variables in the analysis. \n",
    "    - Allows you to keep the observation and not lose the rest of its information.\n",
    "    - Easy. Works well for both prediction and causal inference. (I've done this in many projects.)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eac6346-43ef-4909-a59c-ab943ff3b3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame({\"A\":[12, 4, 5, None, 1], \n",
    "                   \"B\":[None, 2, 54, 3, None], \n",
    "                   \"C\":[20, 16, None, 3, 8], \n",
    "                   \"D\":[14, 3, None, None, 6]}) \n",
    "\n",
    "_df1 = df.copy()\n",
    "_df1['firm'] = 1\n",
    "_df1['date'] = _df1.index\n",
    "\n",
    "_df2 = df.copy()\n",
    "_df2['firm'] = 2\n",
    "_df2['date'] = _df2.index\n",
    "\n",
    "df2 = pd.concat([_df1, _df2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8e48a6-5dc6-4cdf-b9dd-139c1770e048",
   "metadata": {},
   "source": [
    "## Warm up\n",
    "\n",
    "Play around with each of the functions on `df`. Look at the possible parameters each can take, and try a few. \n",
    "\n",
    "(Don't change the underlying data yet, just use the functions without assigning the output to a new object.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2966de17-76c6-4439-9864-52fb89d75f0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8e4cd14e-3c57-4344-afa2-8d86097fb450",
   "metadata": {},
   "source": [
    "## Questions for df:\n",
    "\n",
    "Fill all missing values with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a091c902-076b-4a73-baae-b98ec8dbd281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2bcbadc1-1310-47b9-9b3c-9d07b027e20b",
   "metadata": {},
   "source": [
    "Fill missing values for variable “B” with -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ed38a6-97ff-4e17-9be1-aa389a91e90a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a7d7d75-09fb-4feb-b827-999921332be4",
   "metadata": {},
   "source": [
    "Fill all values with the mean for the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9cf6240-65b5-410b-a5a4-23dd454f7d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "985f4825-dcdf-4493-866e-3ab30b366f23",
   "metadata": {},
   "source": [
    "Fill all values with the median for the variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944ad8b8-38ce-4ce3-a907-60ce4d4cf827",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aeca9359-d939-4d53-ae5d-d1cd45ce5811",
   "metadata": {},
   "source": [
    "Fill values by taking the most recent non-missing prior value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49218b28-258f-4132-9f83-75c43114e7f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee784170-4ae5-454a-91ac-9f4f1c41d712",
   "metadata": {},
   "source": [
    "## Questions for df2:\n",
    "\n",
    "Carry missing values forward without carrying values from firm 1 to firm 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7af36d-59f9-4955-9034-c1d16609dc20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c4a8183-1ca8-4e20-8b67-6591e4aec71c",
   "metadata": {},
   "source": [
    "Fill missing values with the average for firms on that date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfb4778-22cf-4e66-9554-d48ea8d79a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df5e3fd0-140c-46a0-a2cf-839cb2a7d196",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "[Let's look at Anscombes quartet again.](https://ledatascifi.github.io/ledatascifi-2024/content/03/05d_outliers.html#example-2-visual-intuition)\n",
    "\n",
    "--> Outliers _can_ cause analysis to mistate relationships\n",
    "\n",
    "## Outliers exercises (in class)\n",
    "\n",
    "What can we do to find outliers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ec1cb2-d90a-4bdf-8bce-7cd418ba3851",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e0db9d58-33fd-47e1-88fd-0b5e11f5bab2",
   "metadata": {},
   "source": [
    "## Dealing with outliers\n",
    "\n",
    "To paraphrase @ChelseaParlatt: We don't remove or change outliers because they are extreme. Remove them because they aren't part of the data generating process (DGP) you want to study. (\"How are X and Y related, **on average**?\") \n",
    "\n",
    "After finding them, investigate outliers. (This requires domain knowledge and costs time + effort. But necessary for valid analysis!)\n",
    "- If they are errors, fix or remove.\n",
    "- If they are from another DGP, remove (censor). \n",
    "- If they are correct and from the DGP you are interested in, keep. \n",
    "\n",
    "## Doing analysis with extreme values\n",
    "\n",
    "As our quartet showed, extreme values can influence your analysis. You want to know $E(Y|X)$ but outliers can weigh on some kinds of analysis so that your result reflects the outliers more than the central tendencies. \n",
    "\n",
    "[Play with this.](https://ledatascifi.github.io/ledatascifi-2024/content/03/05d_outliers.html#example-2-visual-intuition)\n",
    "\n",
    "Practically, this is solved by applied researchers three ways:\n",
    "\n",
    "1. Winsorize: Any variable above or below some extreme limit is changed to that limit\n",
    "    - Q1: What cutoff? p0.1, p1, or p5?\n",
    "    - Q2: Is the cutoff set using all observations, or within subgroups? \n",
    "        - It matters if the distribution shifts over time or across groups. \n",
    "        - Viz ex: Shifting ridgeline + fixed limit. \n",
    "        - Word ex: If you winsorize \"extremely low\" GDP per capita at $250 USD, you'll change no countries today, but many countries in prior years.\n",
    "1. Transform\n",
    "    - log(), a la Assignment 2 - **by far most common**\n",
    "        - Many variables are ~lognormal (income, etc)\n",
    "        - Interpretation often easier (proportions and elasticities, covered later)\n",
    "    - Others: z-score, Inverse hyperbolic sine, Box-Cox, square root, exponential, \n",
    "    - Normalization on the (0, 1) interval: max/min, sigmoidal, hyperbolic tangent.\n",
    "1. Use an estimator that is robust to outliers\n",
    "    - [Hot, recent research](https://www.sciencedirect.com/science/article/abs/pii/S0304405X2200174X) on issues with the log transformation and an estimator that solves the issue without the transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244fe2d9-7dba-42c9-b355-a6a4df60700e",
   "metadata": {},
   "source": [
    "## Outliers exercises (after class)\n",
    "\n",
    "[Load CCM](https://ledatascifi.github.io/ledatascifi-2024/content/03/05d_outliers.html#finding-outliers).\n",
    "\n",
    "1. Get the correlation between `mb` and `prodmktfluid`.\n",
    "1. Create a variable called `mb_win1` and `prodmktfluid_win1` using the default values of `winsorizer_with_missing()`.\n",
    "1. Get the correlation between `mb_win1` and `prodmktfluid_win1`.\n",
    "1. Let me know what you found!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0496ccc-1ca7-4551-98a2-be2339e105b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4a11f196-d48d-4276-aeb5-082a99698035",
   "metadata": {},
   "source": [
    "Load the 2020 slice of Compustat that we used on Assignment 2. \n",
    "1. Plot the kde of the raw assets variable.\n",
    "1. Plot the kde of the log assets variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6055fec4-aa32-4f9c-9ac9-5f8581e71519",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b989d584-267a-4eb7-aae0-ff7c203dd019",
   "metadata": {},
   "source": [
    "## A short list of problem when filling missing values\n",
    "\n",
    "(I'm including this because it was promised above.)\n",
    "\n",
    "1. Which \"other observations\" to fill based on? All? A subset?\n",
    "    - Imagine you're filling the \"height\" variable. \n",
    "    - Same gender? Same age? Same gender and age?\n",
    "1. Still, is your subset of comparable obs \"enough\". Birth year? Birth country? Ethnicity?\n",
    "1. If you do this for many variables one at a time, separately, that means you're not using the covariance between variables... \n",
    "1. What if missing values are missing for systematic reasons?\n",
    "\n",
    "This is not an exhaustive list. \n",
    "\n",
    "## Acknowledgments \n",
    "\n",
    "Material remixed from many sources, but punched up this year with stuff from:\n",
    "- Rauli Susmel ([censoring](https://www.bauer.uh.edu/rsusmel/phd/ec1-23.pdf))\n",
    "- @ChelseaParlett (DGP quote)\n",
    "- [Nick Hagerty](https://github.com/msu-econ-data-analytics/course-materials)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
