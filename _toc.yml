# Table of contents
#
# possible external link:
# - url: http://espn.com 
#
# Can override a title:
# title: A special title  
#
# Learn more at https://jupyterbook.org/customize/toc.html
#
#################################################

- file: content/frontpage # the index must be a single file, no way around it!


- part: Syllabus
  chapters:
  - file: content/about/objectives
  - file: content/about/outcomes
    title: "Outcomes"
  - file: content/about/about_us
    title: "About us + office hours" 
  - file: content/about/structure_and_policies
  - file: content/about/use_of_gpt
    title: "ChatGPT and other AI" 
  - file: content/about/gradeoverview
  - file: content/about/interest
  - file: content/about/bootcamp
  - file: content/about/hall_of_awesomeness
  - file: content/about/acknowledgments
  
- part: Schedule, tips, resources
  chapters:
  - file: content/about/schedule
    title: "Dashboard, key links, schedule"
  - file: content/about/help
    title: "Help"
  - file: content/about/resources
    title: "Resources"
  - file: content/about/tips
  - url: "https://github.com/LeDataSciFi/ledatascifi-2024/tree/main/community_codebook"
    title: Community Codebook
  - url: "https://github.com/LeDataSciFi/ledatascifi-2024/tree/main/handouts"
    title: Class Handouts

- part: Assignments and participation  
  chapters:
  - file: content/assignments/howto_do
    title: "How to start and turn in assignments"
  - file: content/assignments/howto_review 
    title: "How to do your peer reviews"
  - file: content/assignments/mid_proj 
    title: "Midterm project AKA ASGN 5"
  - file: content/assignments/website_setup 
    title: "Personal Website AKA ASGN 9"  
  - file: content/assignments/project 
    title: "Final projects"
    
- part: Textbook 
  numbered: true # will number the chapters and sections INSIDE the part(s) below
  chapters:  
  - file: content/01/00_Getting_Started
    title: "Motivation and Getting Started"
    sections:
    - file: content/01/01_Motivation
      title: "Motivation"
    - file: content/01/02_Setup
    - file: content/01/03_github
    - file: content/01/03a_githubworkflow
    - file: content/01/04_Markdown
    - file: content/01/05_jupyterlab
      title: "Jupyter Lab Basics"    
    - file: content/01/06_python
      title: "Python Basics"    
    - file: content/01/07_debugging
      title: "Debugging"    
    - file: content/01/07a_errors
    - file: content/01/08_libraries
    - file: content/01/09_gitignore
      title: "Gitignore Files"    
    
  - file: content/02/10_Golden_1
    title: "Good Analysis Practices"
    sections:
    - file: content/02/10_Golden_2
      title: "A case study of bad research"
    - file: content/02/10_Golden_3
      title: "The golden rules"
    - file: content/02/10_Golden_6
      title: "Organizing your projects"
    - file: content/02/10_Golden_7
      title: "Filepaths"
    - file: content/02/10_Golden_4
      title: "Storing data smartly"
    - file: content/02/10_Golden_5a
      title: "Functions"
    - file: content/02/10_Golden_5b
      title: "Writing good code comments"
    - file: content/02/10_Golden_8
    
  - file: content/03/00_Data_Wrangling_Intro
    title: "Wrangling with Data"
    sections:
    - file: content/03/01_Numpy
      title: "Numpy"
      sections:
      - file: content/03/01a_NumpyCS
        title: "Numpy + Scientific Computing"
      - file: content/03/01b_NumpyBasics
        title: "A (Very) Short Introduction"
      - file: content/03/01c_NumpyPractice
        title: "Exercises"
      - file: content/03/01d_NumpyResources
        title: "More Resources"
    - file: content/03/02a_pandasIntro
      title: "Pandas"
      sections:
      - file: content/03/02a_pandasTips
        title: "Tips"      
      - file: content/03/02b_pandasVocab
        title: "Vocab and Long vs Wide Data"      
      - file: content/03/02c_commonFcns
        title: "Common Functions"      
      - file: content/03/02d_temp
        title: "Temp. vs Perm. Objects"      
      - file: content/03/02e_eda_golden
        title: "Golden Rules + EDA"      
      - file: content/03/02f_chains
        title: "Pandas Chains" 
      - file: content/03/02g_commontasks
        title: "Common Tasks" 
      - file: content/03/02h_exercises
        title: "Exercises" 
      - file: content/03/02j_resourcesAndSum
        title: "Summary and Resources" 
    - file: content/03/04a-dataviz
      title: "Data Visualization"
      sections:
      - file: content/03/04b-whyplot
      - file: content/03/04c-makeplot
      - file: content/03/04d-whichplot
      - file: content/03/04e-visualEDA
      - file: content/03/04e2-visualEDA-tools
      - file: content/03/04f1-viz_narrative
      - file: content/03/04f2-customizing_figs
      - file: content/03/04f3-interactive_figs
      - file: content/03/04f4-exercises
      - file: content/03/04h_Summary
    - file: content/03/05a-otherskills
      sections:
      - file: content/03/05b_merging
      - file: content/03/05c_missingdata
      - file: content/03/05d_outliers
      - file: content/03/05e_summary
     
  - file: content/04/00_World_Wide_Data
    title: "Building and Using Large (Textual) Data"
    sections:
    - file: content/04/01_Intro_to_scraping
      title: "Getting Data off the Web"
    - file: content/04/01a_openingAndParsing
    - file: content/04/01b_spiders
      title: "Building a spider" 
    - file: content/04/02_strings
      title: "Exploiting Textual Data" 
      sections:
      - file: content/04/02a_Python Strings
      - file: content/04/02b_regex
      - file: content/04/02c_developing_a_regex
      - file: content/04/02d_RegexApplication
# now that they can scrape, a new world opens up: https://sec-edgar-downloader.readthedocs.io/en/latest/#quick-start        

  - file: content/05/00_intro
    title: "Data Science Intro"    
    sections:
    - file: content/05/01_bigpicture
    - file: content/05/01b_model_process
    - file: content/05/01a_MLgonewrong          
    - file: content/05/01c_teams
    - file: content/05/01d_sharingBigFiles
  - file: content/05/02_reg
    sections:
      - file: content/05/02a_basics   
      - file: content/05/02b_mechanics
      - file: content/05/02c_goodnessOfFit
      - file: content/05/02d_interpretingCoefs
      - file: content/05/02e_statisticalSig 
      - file: content/05/02f_warnings
      # (opt, future?) selection, measurement, omitted variables (HIGH level)
      # (opt, future?) exercises (and answers)
      - file: "content/05/02g_summary"          
  - file: content/05/03_ML
    title: "ML - Intro & Discussion"
    sections:
    - file: content/05/03a_ML_obj_and_tradeoff  
    - file: content/05/03f_leakage
    - file: content/05/03f_leakage3
    - file: content/05/03f_leakage2     
    - file: content/05/03c_ModelEval 
    - file: content/05/03c1_OOS 
    - file: content/05/03d_whatToMax   # need auc/roc
    - file: content/05/03e_whichModel  # need lots more!   
  - file: content/05/04a_SKLearn   
    title: "ML - Code & Implementation"
    sections:
    - file: content/05/04b_best_practices # add extra section for best practices
      title: "Best Practice Pseudo Code"        
    - file: content/05/04c_onemodel
      title: "SKLearn Intro"                             
    - file: content/05/04d_crossval
      title: "Cross-Validation"
    - file: content/05/04e_pipelines
      title: "Pipelines"
    - file: content/05/04e1_preprocessing
      title: "Preprocessing"  
    - file: content/05/04f_optimizing_a_model
      title: "Optimizing a Model"            
    - file: content/05/04h_putting_together
      title: "Many Models" 
  - file: content/05/05a_finapps        
    sections:        
    - file: content/05/05a_compounding
      title: "Compounding returns" 
    - file: content/05/05a_rolling
    - file: content/05/05a_expanding
    - file: content/05/05b_capm
      title: "Estimating CAPM" 
    - file: content/05/05c_factorloadings
      title: "Estimating better models" 
    - file: content/05/05c_finpacks
        
# import smattering? (from below)
# gradient booksting from L24 2020

  - file: content/05/06_thefuture
    sections:        
    - file: content/05/06a_saving
    - file: content/05/06b_nextsteps
    - file: content/05/06c_dashboards
    
- part: Slides and Memes
  chapters:
  - file: content/slides/slides
  - file: content/slides/memes
  

# #########################################################


# # ## A bunch of import statements 

# # Any code you write might use none of these, some of these, or all of them!

# # # dataset loader
# # from sklearn import datasets

# # # model training and evalutation utilities 
# # from sklearn.model_selection import train_test_split
# # from sklearn.model_selection import cross_validate, GridSearchCV
# # from sklearn.model_selection import StratifiedKFold # this is one way to generate folds
# # from sklearn.model_selection import KFold

# # # metrics
# # from sklearn import metrics
# # from sklearn.metrics import r2_score
# # from sklearn.metrics import accuracy_score
# # from sklearn.metrics import classification_report
# # from sklearn.metrics import confusion_matrix

# # # preprocessing and feature extraction
# # from sklearn.pipeline import Pipeline, make_pipeline
# # from sklearn.compose import ColumnTransformer, make_column_selector
# # from sklearn import preprocessing
# # from sklearn.preprocessing import StandardScaler, OneHotEncoder
# # from sklearn.feature_extraction import DictVectorizer
# # from sklearn.impute import SimpleImputer
# # from df_after_transform import df_after_transform # df_after_transform.py must be in this folder

# # # feature selection
# # from sklearn.linear_model import ElasticNet, Lasso, Ridge
# # from sklearn.feature_selection import SelectKBest, RFE, RFECV,

# # # models
# # from sklearn.svm import SVC
# # from sklearn.neighbors import KNeighborsClassifier
# # from sklearn.linear_model import LinearRegression
# # from sklearn import linear_model
# # from sklearn.linear_model import LogisticRegression
# # from sklearn.tree import DecisionTreeClassifier
# # from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
# # from sklearn.naive_bayes import GaussianNB

# # # toy data
# # X, y = datasets.load_iris(return_X_y=True)
# # X.shape, y.shape



####################

# l23 exercises 
# 
# reg with some vars, then Add 5 new continuous variables to your pipeline and see how the R2 changes
#
# implement rfecv - what vars should we choose? implement
